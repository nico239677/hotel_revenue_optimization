{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import datetime\n",
    "from dateutil import parser\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose as sd\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.arima_model import ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyxlsb import open_workbook as open_xlsb\n",
    "df = []\n",
    "\n",
    "with open_xlsb('database/19-01-04_Séjours_2018.xlsb') as wb:\n",
    "    with wb.get_sheet(1) as sheet:\n",
    "        for row in sheet.rows():\n",
    "            df.append([item.v for item in row])\n",
    "\n",
    "df = pd.DataFrame(df[1:], columns=df[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2018 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2019 = pd.read_excel('database/20-01-02_Séjours_2019.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "months = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']\n",
    "months_occ = ['March', 'April', 'May', 'June', 'July', 'August', 'September', 'October']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Analysis Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serial_date_to_string(srl_no):\n",
    "    new_date = datetime.datetime(1900,1,1,0,0) + datetime.timedelta(srl_no - 1)\n",
    "    date_parsed = parser.parse(new_date.strftime(\"%Y-%m-%d\"))\n",
    "    return date_parsed\n",
    "\n",
    "    \n",
    "def epoch_day_to_time(srl_no):\n",
    "    new_date = datetime.datetime(1900,1,1,0,0) + datetime.timedelta(srl_no - 1)\n",
    "    return new_date.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # \n",
    "\n",
    "def camp_occ_calculator(df, camp, plot=True):\n",
    "    \"\"\"\n",
    "    gets df and camp name to calculate daily occ per specific date convertor.\n",
    "    \n",
    "    \"\"\"\n",
    "    df_camp = df[df['camping_label'] == camp]\n",
    "    \n",
    "    if np.dtype(df_camp['datein']) == float:\n",
    "        df_camp['new_date_in'] = df_camp['datein'].apply(lambda x: serial_date_to_string(x))\n",
    "        df_camp['new_date_out'] = df_camp['dateout'].apply(lambda x: serial_date_to_string(x))\n",
    "    else:\n",
    "        df_camp['new_date_in'] = df_camp['datein']\n",
    "        df_camp['new_date_out'] = df_camp['dateout']\n",
    "\n",
    "    season = pd.date_range(start=min(df_camp['new_date_in']),end=max(df_camp['new_date_out']))\n",
    "    dict_dates = defaultdict(int)\n",
    "    for date in season:\n",
    "        dict_dates[date] = 0\n",
    "\n",
    "    for index in df_camp.index:\n",
    "        for j in range(int(df_camp['los'][index])):\n",
    "            dict_dates[pd.Timestamp(df_camp['new_date_in'][index]) + pd.DateOffset(days=j)] += 1\n",
    "    df_date = pd.DataFrame(index=dict_dates.keys(), data=dict_dates.values())\n",
    "    df_date = df_date[df_date[0] != 0]\n",
    "    \n",
    "    if plot:\n",
    "        plot_occ(df_date, camp)\n",
    "        plot_daliy_occ(df_date)\n",
    "        plot_daliy_occ(df_date, time='day')\n",
    "        \n",
    "    return df_date\n",
    "\n",
    "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # \n",
    "\n",
    "def plot_occ(df, camp):\n",
    "    \"\"\"\n",
    "    plot summarize occ data per interval\n",
    "    \"\"\"\n",
    "    interval = ['M', 'd']\n",
    "    year = list(map(str, (df.index.year.min(), df.index.year.max())))\n",
    "    for i, t in enumerate(interval, 1):\n",
    "        plt.subplot(1,2,i)\n",
    "        df[0].resample(t).mean().plot(figsize=(15,5))\n",
    "        plt.title(camp, fontsize=20)\n",
    "        plt.ylabel('Occ')\n",
    "        \n",
    "\n",
    "def plot_daliy_occ(df, time=None):\n",
    "    \"\"\"\n",
    "    Gets Avg Occ per month for date indexed df\n",
    "    params: df of specific camp for specific year\n",
    "            time, if None plot by day of the month else by week\n",
    "    return: daily avg occ plot\n",
    "    \"\"\"\n",
    "    if time != None:\n",
    "        time = df.index.dayofweek\n",
    "        x_label = \"Days of Week\" \n",
    "    else:\n",
    "        time = df.index.day\n",
    "        x_label = \"Days of Month\" \n",
    "        \n",
    "    df.groupby([time, df.index.month]).mean().unstack().plot(figsize=(10,5), label='Inline label')\n",
    "    plt.title('Daily Occ')\n",
    "    plt.ylabel('OCC')\n",
    "    plt.xlabel(x_label)\n",
    "    plt.legend(months, loc='best', bbox_to_anchor=(1,1))\n",
    "\n",
    "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # \n",
    "\n",
    "def run_predictor(train, test, model, test_year=2019):\n",
    "    \"\"\"\n",
    "    Combine train and test df i.e. past and the test future df, using specified model.\n",
    "    shift data by 10 days to prepare new data frame for autoregressor models.\n",
    "    params: train, past years of camp occupations data\n",
    "            test, future year to test model on \n",
    "    returns: prediction score and sanity checks for splited data.\n",
    "    \"\"\"\n",
    "    df = train.append(test)\n",
    "    print(f'Dates range:\\n{df.index.min()} - {df.index.max()}\\n')\n",
    "    shifted_data = pd.DataFrame({f't{k}': df[0].shift(k) for k in range(30)})\n",
    "    shifted_data = shifted_data[~shifted_data.isna().any(axis=1)]\n",
    "    X = shifted_data.drop(columns='t0')\n",
    "    y = shifted_data.t0\n",
    "    print(*list(zip(('X shape: ', 'y shape: '), (X.shape, y.shape))), sep='\\n')\n",
    "\n",
    "    # Split Train Test\n",
    "    X_train = X[X.index.year != test_year]\n",
    "    X_test = X[y.index.year == test_year]\n",
    "    y_train = y[X.index.year != test_year]\n",
    "    y_test = y[y.index.year == test_year]\n",
    "    print(*list(zip(('X_train shape: ', 'X_test shape: ', 'y_train shape: ', 'y_test shape: '),(X_train.shape, X_test.shape, y_train.shape, y_test.shape))), sep='\\n')\n",
    "    \n",
    "    # Run predictor\n",
    "    if model == ARIMA:\n",
    "        reg = model(X_train, order=(1,1,1))\n",
    "        reg.fit()\n",
    "    else:\n",
    "        reg = model()\n",
    "        \n",
    "    reg.fit(X_train, y_train)\n",
    "    y_pred = reg.predict(X_test)\n",
    "    print(f'R2:\\t{round(r2_score(y_test, y_pred),3)}\\nRMSE:\\t{round(mean_squared_error(y_test, y_pred),2)}')\n",
    "    \n",
    "        \n",
    "    f, a = plt.subplots(1,1,figsize = (10,5), sharex=True)\n",
    "    plt.plot(y_test.index.month, y_test, label='Observed')\n",
    "    plt.plot(y_test.index.month, y_pred, label='Forecast')\n",
    "    plt.ylabel('Occ.')\n",
    "    plt.xlabel('Date')\n",
    "    plt.title('Prediction vs Past model Evaluation')\n",
    "    plt.legend()\n",
    "    \n",
    "    \n",
    "#     return X_train, X_test, y_train, y_test\n",
    "\n",
    "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis Per Camp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gavina_2018 = camp_occ_calculator(df_2018, \"GAVINA\")\n",
    "df_gavina_2019 = camp_occ_calculator(df_2019, \"GAVINA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.plotting.autocorrelation_plot(df_gavina_2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pacf(df_gavina_2018);\n",
    "plot_acf(df_gavina_2018);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5));\n",
    "sd(df_gavina_2018, model='additive', freq=30).seasonal.plot(legend=False);\n",
    "sd(df_gavina_2018, model='additive', freq=30).trend.plot(legend=False);\n",
    "sd(df_gavina_2018, model='additive', freq=30).resid.plot(legend=False);\n",
    "\n",
    "# plt.legend(loc='upper right', bbox_to_anchor=(1.3, 1), fontsize=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = run_predicator(df_gavina_2018, df_gavina_2019, RandomForestRegressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All Camps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camps = df['camping_label'].unique().tolist()[:10]\n",
    "error = []\n",
    "for camp in camps:\n",
    "    try:\n",
    "        print(f\"\\n\\nTrain TS Analysis On 2018 {camp} Occ.\\n\\n\")\n",
    "        train = camp_occ_calculator(df_2018, camp)\n",
    "        plt.show()\n",
    "        print(f\"\\n\\nTest TS Analysis On 2019 {camp} Occ.\\n\\n\")\n",
    "        test = camp_occ_calculator(df_2019, camp)\n",
    "        plt.show()\n",
    "        predict = run_predicator(train, test, RandomForestRegressor)\n",
    "    except Exception as e:\n",
    "        print(f\"\\n\\nError {e} for {camp}\\n\\n\")\n",
    "        error.append(camp)\n",
    "print(error)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
